{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoICCv8BCikvaWJjLmFwcGxpY2F0aW9ucy50cmFuc2Zlci52MS5Nc2dUcmFuc2ZlchLRAQoIdHJhbnNmZXISCmNoYW5uZWwtNjAaUQpEaWJjL0JDNUMwQkFGRDE5QTVFNDEzM0ZEQTBGM0UwNEFFMUZCRUU3NUE0QTIyNjU1NEIyQ0JCMDIxMDg5RkYyRTFGOEESCTMwMDAwMDAwMCIubWlnYWxvbzE1NGpneGU1ZHFhYWM1dWZxeXk1dTNqdXA3dXRhaGszZ3BzOGw4aCosbm9ibGUxNTRqZ3hlNWRxYWFjNXVmcXl5NXUzanVwN3V0YWhrM2d5OG1kMmg4gNTjoszUpt0XEmsKUQpGCh8vY29zbW9zLmNyeXB0by5zZWNwMjU2azEuUHViS2V5EiMKIQOILGZNtq9bh6xuHiOeMX+qX9FwwA+EoP/VXIEtoQNwzhIECgIIARioOBIWChAKBnV3aGFsZRIGMTUwMDAwEPCTCRpAqg4oRPwLF92M7X7sfhyoUYVhjnBF6YSQEVthwQvZI0wVINULhIHetOQHDM+C6JfBwtTIscLMAVeDCp1z2OlPoQ==CtAFCrMFCiQvY29zbXdhc20ud2FzbS52MS5Nc2dFeGVjdXRlQ29udHJhY3QSigUKLm1pZ2Fsb28xN3hraGFlcGg5Y3VrNXlobXFnY3gzM3pqbjgyc2d6cDB3dnEweXUSQm1pZ2Fsb28xdG1hMjhleHAzOHE5MmM2OXI4dXVqaHBoeHk5NXhhNGF3cTJjdWRxcWczbmh6a2hucmc1czRyNjBlbhq/A3siZXhlY3V0ZV9zd2FwX29wZXJhdGlvbnMiOnsib3BlcmF0aW9ucyI6W3sidGVycmFfc3dhcCI6eyJvZmZlcl9hc3NldF9pbmZvIjp7Im5hdGl2ZV90b2tlbiI6eyJkZW5vbSI6ImliYy9FNDlBNkQxMTY3MzlFMDkyMEY4RjJENjhBOEYwQThFMDdEQzI3MkZBMTQyMUY3MENBRDczODQ2M0FBMjk2NzI0In19LCJhc2tfYXNzZXRfaW5mbyI6eyJuYXRpdmVfdG9rZW4iOnsiZGVub20iOiJ1d2hhbGUifX19fSx7InRlcnJhX3N3YXAiOnsib2ZmZXJfYXNzZXRfaW5mbyI6eyJuYXRpdmVfdG9rZW4iOnsiZGVub20iOiJ1d2hhbGUifX0sImFza19hc3NldF9pbmZvIjp7Im5hdGl2ZV90b2tlbiI6eyJkZW5vbSI6ImliYy9CQzVDMEJBRkQxOUE1RTQxMzNGREEwRjNFMDRBRTFGQkVFNzVBNEEyMjY1NTRCMkNCQjAyMTA4OUZGMkUxRjhBIn19fX1dLCJtaW5pbXVtX3JlY2VpdmUiOiI2NzQ2NDAwMCJ9fSpSCkRpYmMvRTQ5QTZEMTE2NzM5RTA5MjBGOEYyRDY4QThGMEE4RTA3REMyNzJGQTE0MjFGNzBDQUQ3Mzg0NjNBQTI5NjcyNBIKNDQ3MzI4MDAwMBIYNjYtbWlnYWxvb0JvdC0yMDI0LTAzLTA3EmwKUQpGCh8vY29zbW9zLmNyeXB0by5zZWNwMjU2azEuUHViS2V5EiMKIQKRKIOTGiVgISEZl85tA8ihVO8rN1KU+5cau31MocwFjhIECgIIARi4ZBIXChEKBnV3aGFsZRIHMTA0MjE5ORCXzj8aQNUS0s5JLQymJyRTvs081qDCuAnCNWjAlg0KmSgM/5sQTXlQlIMWBB3VhfY81f+lmp/ZEFaNGkHSc5HFxD3YU3s=\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def process_transaction_data(file_path): # Assign encrypted object to variable\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            transaction = data['block']['data']['txs']\n",
    "\n",
    "            if len(transaction) > 0:\n",
    "                return ''.join(map(str, transaction))  # Remove unnecessary symbols\n",
    "            else:\n",
    "                return \"No transactions found.\"\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "block_number = '5846136'  # Change this number if you want to load a different file\n",
    "file_path = f'C:/Users/lmhmo/indexer/blocks/{block_number}.json'\n",
    "code = process_transaction_data(file_path)\n",
    "print(code)\n",
    "# %%"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:01.590651300Z",
     "start_time": "2024-03-11T20:46:01.575309700Z"
    }
   },
   "id": "1ecf0e15b452550e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 1\n",
      "Transaction 1 decoded and saved to 5846136_1.json\n",
      "5846136_1.json\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Destination path 'C:/Users/lmhmo/indexer/Decrypted_files\\5846136_1.json' already exists",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mError\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 41\u001B[0m\n\u001B[0;32m     39\u001B[0m target_directory \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:/Users/lmhmo/indexer/Decrypted_files\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Move the file\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmove\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_directory\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m moved to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_directory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:860\u001B[0m, in \u001B[0;36mmove\u001B[1;34m(src, dst, copy_function)\u001B[0m\n\u001B[0;32m    857\u001B[0m     real_dst \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dst, _basename(src))\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(real_dst):\n\u001B[1;32m--> 860\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Error(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDestination path \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m already exists\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m real_dst)\n\u001B[0;32m    861\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    862\u001B[0m     os\u001B[38;5;241m.\u001B[39mrename(src, real_dst)\n",
      "\u001B[1;31mError\u001B[0m: Destination path 'C:/Users/lmhmo/indexer/Decrypted_files\\5846136_1.json' already exists"
     ]
    }
   ],
   "source": [
    "# Decrypt transaction using base64 api\n",
    "import requests\n",
    "\n",
    "def decode_transactions(tx, block, i):\n",
    "    url = \"https://phoenix-lcd.terra.dev/cosmos/tx/v1beta1/decode\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = json.dumps({\"tx_bytes\": tx})\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data)  # Send to be decoded\n",
    "    decoded_response = response.json()\n",
    "\n",
    "    # Save the decoded data to a JSON file\n",
    "    filename = f\"{block}_{i + 1}.json\"\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json.dump(decoded_response, json_file, indent=2)\n",
    "\n",
    "    print(f\"Transaction {i + 1} decoded and saved to {filename}\") # Assign to json file\n",
    "    return filename\n",
    "\n",
    "# Example usage\n",
    "code = code.split()\n",
    "many = len(code)\n",
    "block = block_number\n",
    "\n",
    "print(f\"Number of transactions: {many}\")\n",
    "\n",
    "# Store generated filenames in a list\n",
    "generated_filenames = []\n",
    "for i in range(many):\n",
    "    filename = decode_transactions(code[i], block, i)\n",
    "    generated_filenames.append(filename)\n",
    "\n",
    "print(filename)\n",
    "# %%\n",
    "# This section of code will send the new decrypted json file to the decrypted_files directory\n",
    "import shutil\n",
    "\n",
    "# Specify the target directory\n",
    "target_directory = \"C:/Users/lmhmo/indexer/Decrypted_files\"\n",
    "# Move the file\n",
    "shutil.move(filename, target_directory)\n",
    "print(f\"File '{filename}' moved to '{target_directory}'.\")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:03.259635900Z",
     "start_time": "2024-03-11T20:46:02.710214600Z"
    }
   },
   "id": "bf69b4e1d4421d55",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       @type source_port source_channel  \\\n",
      "0  /ibc.applications.transfer.v1.MsgTransfer    transfer      channel-8   \n",
      "\n",
      "                                           sender  \\\n",
      "0  migaloo1mmr2gl33xftfcejemw2etcdz7gsmraq6x8jjhv   \n",
      "\n",
      "                                        receiver    timeout_timestamp memo  \\\n",
      "0  kujira1mmr2gl33xftfcejemw2etcdz7gsmraq66mes0g  1709844691623000000        \n",
      "\n",
      "  token.denom token.amount timeout_height.revision_number  ...  \\\n",
      "0      uwhale   1730074000                              0  ...   \n",
      "\n",
      "                  public_key.@type  \\\n",
      "0  /cosmos.crypto.secp256k1.PubKey   \n",
      "\n",
      "                                 public_key.key mode_info.single.mode   denom  \\\n",
      "0  A0BOCvcS7adOdSbQ+fHN4rcVHVHOZ/6JTjRH5zaowzPx      SIGN_MODE_DIRECT  uwhale   \n",
      "\n",
      "   amount                                         signatures gas_limit payer  \\\n",
      "0  150000  Elf4xFmpRlp5G38j3fgeoNGeC9f9IA46cXmgogRRg+Yp91...    150000         \n",
      "\n",
      "  granter   tip  \n",
      "0          None  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This section of code uses json and pandas to clean json file and get it ready to sort it into a tabular format to prepare for postgres\n",
    "import pandas as pd\n",
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\lmhmo\\indexer\\Decrypted_files\\5845389_1.json'\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Slight modifications made to make data postgres friendly\n",
    "def replace_empty_strings(item):\n",
    "    return \"N/A\" if item == \"null\" else item\n",
    "\n",
    "for field in [\"sender\", \"receiver\", \"memo\"]:\n",
    "    json_data[\"tx\"][\"body\"][\"messages\"][0][field] = replace_empty_strings(json_data[\"tx\"][\"body\"][\"messages\"][0][field])\n",
    "# This section of code calls the paths of all the attributes needs for the postgres table\n",
    "df_messages = pd.json_normalize(json_data[\"tx\"][\"body\"][\"messages\"])\n",
    "df_auth_info = pd.json_normalize(json_data[\"tx\"][\"auth_info\"][\"signer_infos\"])\n",
    "df_fee_info = pd.json_normalize(json_data[\"tx\"][\"auth_info\"][\"fee\"][\"amount\"])\n",
    "df_sig_info = pd.DataFrame({\"signatures\": json_data[\"tx\"][\"signatures\"]})\n",
    "df_gas_info = pd.DataFrame({\"gas_limit\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"gas_limit\"]]})\n",
    "df_payer_info = pd.DataFrame({\"payer\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"payer\"]]})\n",
    "df_granter_info = pd.DataFrame({\"granter\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"granter\"]]})\n",
    "df_tip_info = pd.DataFrame({\"tip\": [json_data[\"tx\"][\"auth_info\"][\"tip\"]]})\n",
    "\n",
    "# Combine dataframes\n",
    "df_combined = pd.concat(\n",
    "    [df_messages, df_auth_info, df_fee_info, df_sig_info, df_gas_info, df_payer_info, df_granter_info, df_tip_info],\n",
    "    axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "print(df_combined)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:15.205994600Z",
     "start_time": "2024-03-11T20:46:12.928304600Z"
    }
   },
   "id": "55d40362480cfaa",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Creates tabular format\n",
    "column_names = list(df_combined.columns)\n",
    "# Slight modifications that needed to be made to prepare for postgres\n",
    "def clean_column_name(col): # Special symbols can not be inside of column names\n",
    "    return col.replace(\"@\", \"\").replace(\" \", \"_\").replace('.', '')\n",
    "\n",
    "column_names_cleaned = [clean_column_name(col) for col in column_names]\n",
    "\n",
    "message = json_data[\"tx\"][\"body\"][\"messages\"][0]\n",
    "table_name = message[\"@type\"].split(\".\")[-1][-10:]\n",
    "table_name = table_name.lower()  # This has to be specified for check_table_query to work\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:20.963199100Z",
     "start_time": "2024-03-11T20:46:20.955532100Z"
    }
   },
   "id": "ed55d431a3276516",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'sgtransfer' already exists. Data will be appended to the existing table.\n",
      "Table 'sgtransfer' already exists. Data will be appended to the existing table.\n",
      "                                       @type source_port source_channel  \\\n",
      "0  /ibc.applications.transfer.v1.MsgTransfer    transfer      channel-8   \n",
      "\n",
      "                                           sender  \\\n",
      "0  migaloo1mmr2gl33xftfcejemw2etcdz7gsmraq6x8jjhv   \n",
      "\n",
      "                                        receiver    timeout_timestamp memo  \\\n",
      "0  kujira1mmr2gl33xftfcejemw2etcdz7gsmraq66mes0g  1709844691623000000        \n",
      "\n",
      "  token.denom token.amount timeout_height.revision_number  ...  \\\n",
      "0      uwhale   1730074000                              0  ...   \n",
      "\n",
      "                  public_key.@type  \\\n",
      "0  /cosmos.crypto.secp256k1.PubKey   \n",
      "\n",
      "                                 public_key.key mode_info.single.mode   denom  \\\n",
      "0  A0BOCvcS7adOdSbQ+fHN4rcVHVHOZ/6JTjRH5zaowzPx      SIGN_MODE_DIRECT  uwhale   \n",
      "\n",
      "   amount                                         signatures gas_limit payer  \\\n",
      "0  150000  Elf4xFmpRlp5G38j3fgeoNGeC9f9IA46cXmgogRRg+Yp91...    150000         \n",
      "\n",
      "  granter   tip  \n",
      "0          None  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to database\n",
    "import psycopg2\n",
    "\n",
    "DB_NAME = 'blockchain'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'auth2020'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "\n",
    "# Create a PostgreSQL connection\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT\n",
    ")\n",
    "# %%\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Check if the table already exists\n",
    "check_table_query = f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT 1\n",
    "        FROM pg_tables\n",
    "        WHERE schemaname = 'public' AND tablename = '{table_name}'\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(check_table_query)\n",
    "table_exists = cur.fetchone()[0]  # Fetch the result of the query\n",
    "\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists. Data will be appended to the existing table.\")\n",
    "else:\n",
    "    print(f\"Table '{table_name}' does not exist. Creating a new table...\")\n",
    "\n",
    "# %%\n",
    "\n",
    "if not table_exists:\n",
    "    # Create the table with dynamic column names (matching cleaned attributes)\n",
    "    create_table_query = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            {', '.join(f\"{column_names_cleaned[i]} VARCHAR(255)\" for i in range(len(column_names)))}, block INTEGER NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    cur.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Table '{table_name}' already exists. Data will be appended to the existing table.\")\n",
    "\n",
    "# Insert data into the table\n",
    "for _, row in df_combined.iterrows():\n",
    "    # Assuming you have already defined the variable block_number\n",
    "    # Modify the INSERT query to include the block number\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} ({', '.join(column_names_cleaned)}, block)\n",
    "        VALUES ({', '.join(f\"'{row.iloc[i]}'\" for i in range(len(column_names)))}, {block});\n",
    "    \"\"\"\n",
    "cur.execute(insert_query)\n",
    "\n",
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T20:46:27.574387400Z",
     "start_time": "2024-03-11T20:46:27.493368200Z"
    }
   },
   "id": "c43fe1dd8fb0e11e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fd80dcea34329c17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
