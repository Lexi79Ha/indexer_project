{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e180ccc31576322",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:36:51.104281400Z",
     "start_time": "2024-03-20T21:36:51.043160100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import logging\n",
    "\n",
    "DB_NAME = 'blockchain'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'auth2020'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a PostgreSQL connection\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    print(\"Connection established.\")  # Log successful connection (you can modify this)\n",
    "\n",
    "    # Configure logging to write to a log file\n",
    "    logging.basicConfig(filename='log.txt', level=logging.INFO)\n",
    "    logging.info(\"Connection established with Database.\")  # Log the same message to the file\n",
    "\n",
    "\n",
    "    # Additional code for database operations goes here...\n",
    "\n",
    "except Exception as err:\n",
    "    # Handle exceptions\n",
    "    print(\"Unable to connect to database.\")  # Log error (you can modify this)\n",
    "    print(err)  # Print the specific error message\n",
    "\n",
    "    # Optionally, write the error message to a file (error.txt)\n",
    "    with open('error.txt', 'a') as error_file:\n",
    "        error_file.write(str(err) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb031dd6bc63e996"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:/Users/lmhmo/Indexer_Project/indexer_project/Decrypted_files/5927808.json' exists. Proceeding with further actions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "block = '5927808'  # Change this number if you want to load a different file\n",
    "file_path = f'C:/Users/lmhmo/Indexer_Project/indexer_project/Decrypted_files/{block}.json'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File '{file_path}' exists. Proceeding with further actions.\")\n",
    "        # Add your additional code here\n",
    "\n",
    "        # Configure logging to write to both log.txt and error.txt\n",
    "        logging.basicConfig(filename='log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        logging.info(f\"File '{file_path}' exists. Proceeding with further actions.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")\n",
    "        # Log the error message to error.txt\n",
    "        with open('error.txt', 'a') as error_file:\n",
    "            error_file.write(f\"File '{file_path}' does not exist.\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Log the error message to error.txt\n",
    "    with open('error.txt', 'a') as error_file:\n",
    "        error_file.write(f\"An error occurred: {e}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:36:51.109721400Z",
     "start_time": "2024-03-20T21:36:51.103282Z"
    }
   },
   "id": "8fae7717f924d9db",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sender'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN/A\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnull\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m item\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m field \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msender\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceiver\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemo\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m---> 14\u001B[0m     json_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtx\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][field] \u001B[38;5;241m=\u001B[39m replace_empty_strings(\u001B[43mjson_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbody\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# This section of code calls the paths of all the attributes needs for the postgres table\u001B[39;00m\n\u001B[0;32m     16\u001B[0m df_messages \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mjson_normalize(json_data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtx\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[1;31mKeyError\u001B[0m: 'sender'"
     ]
    }
   ],
   "source": [
    "# This section of code uses json and pandas to clean json file and get it ready to sort it into a tabular format to prepare for postgres\n",
    "import pandas as pd\n",
    "import json\n",
    "# Specify the file path\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Slight modifications made to make data postgres friendly\n",
    "def replace_empty_strings(item):\n",
    "    return \"N/A\" if item == \"null\" else item\n",
    "\n",
    "for field in [\"sender\", \"receiver\", \"memo\"]:\n",
    "    json_data[\"tx\"][\"body\"][\"messages\"][0][field] = replace_empty_strings(json_data[\"tx\"][\"body\"][\"messages\"][0][field])\n",
    "# This section of code calls the paths of all the attributes needs for the postgres table\n",
    "df_messages = pd.json_normalize(json_data[\"tx\"][\"body\"][\"messages\"])\n",
    "df_auth_info = pd.json_normalize(json_data[\"tx\"][\"auth_info\"][\"signer_infos\"])\n",
    "df_fee_info = pd.json_normalize(json_data[\"tx\"][\"auth_info\"][\"fee\"][\"amount\"])\n",
    "df_sig_info = pd.DataFrame({\"signatures\": json_data[\"tx\"][\"signatures\"]})\n",
    "df_gas_info = pd.DataFrame({\"gas_limit\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"gas_limit\"]]})\n",
    "df_payer_info = pd.DataFrame({\"payer\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"payer\"]]})\n",
    "df_granter_info = pd.DataFrame({\"granter\": [json_data[\"tx\"][\"auth_info\"][\"fee\"][\"granter\"]]})\n",
    "df_tip_info = pd.DataFrame({\"tip\": [json_data[\"tx\"][\"auth_info\"][\"tip\"]]})\n",
    "\n",
    "# Combine dataframes\n",
    "df_combined = pd.concat(\n",
    "    [df_messages, df_auth_info, df_fee_info, df_sig_info, df_gas_info, df_payer_info, df_granter_info, df_tip_info],\n",
    "    axis=1)\n",
    "\n",
    "# Display the combined dataframe\n",
    "print(df_combined)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:36:52.091555Z",
     "start_time": "2024-03-20T21:36:51.110725500Z"
    }
   },
   "id": "c66771214f5e6a89",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creates tabular format\n",
    "column_names = list(df_combined.columns)\n",
    "# Slight modifications that needed to be made to prepare for postgres\n",
    "def clean_column_name(col): # Special symbols can not be inside of column names\n",
    "    return col.replace(\"@\", \"\").replace(\" \", \"_\").replace('.', '')\n",
    "\n",
    "column_names_cleaned = [clean_column_name(col) for col in column_names]\n",
    "\n",
    "message = json_data[\"tx\"][\"body\"][\"messages\"][0]\n",
    "table_name = message[\"@type\"].split(\".\")[-1][-10:]\n",
    "table_name = table_name.lower()  # This has to be specified for check_table_query to work"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T21:36:52.090559300Z"
    }
   },
   "id": "4ed0473d4a0432f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Create a cursor\n",
    "\n",
    "\n",
    "# Check if the table already exists\n",
    "check_table_query = f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT 1\n",
    "        FROM pg_tables\n",
    "        WHERE schemaname = 'public' AND tablename = '{table_name}'\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(check_table_query)\n",
    "table_exists = cur.fetchone()[0]  # Fetch the result of the query\n",
    "\n",
    "if table_exists:\n",
    "    print(f\"Table '{table_name}' already exists. Data will be appended to the existing table.\")\n",
    "else:\n",
    "    print(f\"Table '{table_name}' does not exist. Creating a new table...\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T21:36:52.091555Z"
    }
   },
   "id": "5801cceed630449e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "if not table_exists:\n",
    "    # Create the table with dynamic column names (matching cleaned attributes)\n",
    "    create_table_query = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            {', '.join(f\"{column_names_cleaned[i]} VARCHAR(255)\" for i in range(len(column_names)))}, block INTEGER NOT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    cur.execute(create_table_query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Table '{table_name}' already exists. Data will be appended to the existing table.\")\n",
    "\n",
    "# Insert data into the table\n",
    "for _, row in df_combined.iterrows():\n",
    "    # Assuming you have already defined the variable block_number\n",
    "    # Modify the INSERT query to include the block number\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} ({', '.join(column_names_cleaned)}, block)\n",
    "        VALUES ({', '.join(f\"'{row.iloc[i]}'\" for i in range(len(column_names)))}, {block});\n",
    "    \"\"\"\n",
    "cur.execute(insert_query)\n",
    "\n",
    "# Commit changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_combined)\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-03-20T21:36:52.092555300Z"
    }
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T21:36:52.093554500Z"
    }
   },
   "id": "7e5dbdd45681e8f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
