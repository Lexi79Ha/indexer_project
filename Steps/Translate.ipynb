{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7533ee2beadf8cf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:00:18.935438200Z",
     "start_time": "2024-04-03T17:00:18.930697400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:/Users/lmhmo/Indexer_Project/indexer_project/blocks/1199803.json' exists. Proceeding with further actions.\n"
     ]
    }
   ],
   "source": [
    "# The variable code is then sent to an api that uses base64 to decrypt the transactions\n",
    "# After the decrypted data is return it is assigned to a new json file in the decrypted_files directory\n",
    "# The json file is then pull from the directory to be cleaned and prepared for postgres migration\n",
    "# The attributes with the json file are pulled and isolated using pandas\n",
    "# libraries: json, requests, shutil, os ,logging\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "\n",
    "block_number = '1199803'  # Change this number if you want to load a different file\n",
    "file_path = f'C:/Users/lmhmo/Indexer_Project/indexer_project/blocks/{block_number}.json'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File '{file_path}' exists. Proceeding with further actions.\")\n",
    "        # Add your additional code here\n",
    "\n",
    "        # Configure logging to write to both log.txt and error.txt\n",
    "        logging.basicConfig(filename='log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        logging.info(f\"File '{file_path}' exists. Proceeding with further actions.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"File '{file_path}' does not exist.\")\n",
    "        # Log the error message to error.txt\n",
    "        with open('error.txt', 'a') as error_file:\n",
    "            error_file.write(f\"File '{file_path}' does not exist.\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    # Log the error message to error.txt\n",
    "    with open('error.txt', 'a') as error_file:\n",
    "        error_file.write(f\"An error occurred: {str(e)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpkCCpYCCiAvYWxsaWFuY2UuYWxsaWFuY2UuTXNnUmVkZWxlZ2F0ZRLxAQoubWlnYWxvbzFsNHJ2a3F4MGwwamhxcnVxeTU3OWpyaDA4Yzd0MGFsa3k4OHlzMBI1bWlnYWxvb3ZhbG9wZXIxOWF2OTNmbGg1MzhlcmpuM3U4Z2ptaHVmYWFhODJ4NmFyNDJyeDUaNW1pZ2Fsb292YWxvcGVyMXJydjZubnQwc3VzdTRhbHR0M202dWQycjg1cWprYzJjdzZwdHd6IlEKRGliYy80MEMyOTE0M0JGNDE1M0IzNjUwODlFNDBFNDM3QjdBQTgxOTY3MjY0NkM0NUJCMEE1RjFFMTA5MTVBMEI2NzA4EgkxOTAzMzE4NjUSagpQCkYKHy9jb3Ntb3MuY3J5cHRvLnNlY3AyNTZrMS5QdWJLZXkSIwohAsA2iwzqTJp5/GJ1ApHg0KqD/ZvAIZue59Ka+v5UazWpEgQKAggBGAcSFgoQCgZ1d2hhbGUSBjIxNjY3NxCR8zQaQKZXn4TWcrkZp6Eqp16HdmaY4kVldNAjPgqWqMSEs7LsFSKPDVtF4ZlgpWPJE34P07FWebwzPz7xRacUn0VmV5s=\n"
     ]
    }
   ],
   "source": [
    "#Isolate txs component of json file and assign it to a variable\n",
    "def process_transaction_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            transaction = data['block']['data']['txs']\n",
    "\n",
    "            if len(transaction) > 0:\n",
    "                return ''.join(map(str, transaction))  # Remove unnecessary symbols\n",
    "            else:\n",
    "                return \"No transactions found.\"\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found.\"\n",
    "\n",
    "# Specify the file path\n",
    "file_path = f'C:/Users/lmhmo/Indexer_Project/indexer_project/blocks/{block_number}.json'\n",
    "\n",
    "try:\n",
    "    code = process_transaction_data(file_path)\n",
    "    print(code)  # Print the result (you can modify this)\n",
    "\n",
    "    # Configure logging to write to both log.txt and error.txt\n",
    "    logging.basicConfig(filename='log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info(f\"Data processed successfully from file '{file_path}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    # Log the error message to error.txt\n",
    "    with open('error.txt', 'a') as error_file:\n",
    "        error_file.write(f\"Error occurred: {str(e)}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:00:18.961660800Z",
     "start_time": "2024-04-03T17:00:18.939438Z"
    }
   },
   "id": "9957aa431cf3fc8a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashed result: DBD3DAE4A238E28D809B346696FCF224C2294A623E1F89A4D7CC7901EA7D2C22\n",
      "Number of transactions: 1\n",
      "Transaction 1 decoded and saved to 1199803.json\n",
      "File '1199803.json' moved to 'C:/Users/lmhmo/Indexer_Project/indexer_project/Decrypted_files'.\n"
     ]
    }
   ],
   "source": [
    "# This section hashes the txs variable and also translates the variable with an api\n",
    "import hashlib\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def hash_to_hex(data: str) -> str:\n",
    "    try:\n",
    "        # Convert data from base64 to bytes\n",
    "        data_bytes = base64.b64decode(data)\n",
    "        # Calculate SHA-256 hash\n",
    "        sha256_hash = hashlib.sha256(data_bytes).hexdigest()\n",
    "        # Convert hash to uppercase\n",
    "        return sha256_hash.upper()\n",
    "    except Exception as e:\n",
    "        print(f\"Error while hashing: {e}\")\n",
    "        return None\n",
    "\n",
    "def decode_transactions(tx: str, block: int, i: int) -> str:\n",
    "    try:\n",
    "        url = \"https://phoenix-lcd.terra.dev/cosmos/tx/v1beta1/decode\"\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        data = json.dumps({\"tx_bytes\": tx})\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        decoded_response = response.json()\n",
    "\n",
    "        # Add hashed_result to the decoded data\n",
    "        decoded_response[\"hashed_result\"] = hashed_result\n",
    "\n",
    "        # Save the updated decoded data to a JSON file\n",
    "        filename = f\"{block}.json\"\n",
    "        with open(filename, \"w\") as json_file:\n",
    "            json.dump(decoded_response, json_file, indent=2)\n",
    "\n",
    "        print(f\"Transaction {i + 1} decoded and saved to {filename}\")\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error while decoding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "code = code # Replace with actual base64-encoded data\n",
    "block_number = block_number # Replace with the block number\n",
    "\n",
    "# Hash the data\n",
    "hashed_result = hash_to_hex(code)\n",
    "print(f\"Hashed result: {hashed_result}\")\n",
    "\n",
    "# Decode transactions\n",
    "code_list = code.split()\n",
    "many = len(code_list)\n",
    "\n",
    "print(f\"Number of transactions: {many}\")\n",
    "\n",
    "# Store generated filenames in a list\n",
    "generated_filenames = []\n",
    "for i, tx in enumerate(code_list):\n",
    "    filename = decode_transactions(tx, block_number, i)\n",
    "    if filename:\n",
    "        generated_filenames.append(filename)\n",
    "\n",
    "# Move the generated JSON files to the \"Decrypted_files\" directory\n",
    "target_directory = \"C:/Users/lmhmo/Indexer_Project/indexer_project/Decrypted_files\"\n",
    "for filename in generated_filenames:\n",
    "    shutil.move(filename, target_directory)\n",
    "    print(f\"File '{filename}' moved to '{target_directory}'.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:00:19.509674400Z",
     "start_time": "2024-04-03T17:00:18.959151700Z"
    }
   },
   "id": "1aaf9ae5972d930c",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:00:19.514677500Z",
     "start_time": "2024-04-03T17:00:19.509674400Z"
    }
   },
   "id": "e02272610782ff6a",
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
